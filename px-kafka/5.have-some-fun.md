In this step, we will start a kafka client and have some fun!

### Step: Start Kafka Client Container

Run the client and in a shell.
```
kubectl create -f kafka-cli.yaml
```{{execute T1}}

Watch to make sure the kafka-cli pod starts.
```
watch kubectl get pods -o wide
```{{execute T1}}

When the Kafka pod is in STATE Running and READY 1/1 then hit ```clear```{{execute interrupt}} to ctrl-c and clear the screen.

### Step:  Create a topic and send + receive messages on it


Start two bash sessions in the kafka-cli pod, one in **Terminal 1** (the producer), and one in **Terminal 2** (the consumer):
```
kubectl exec -it kafka-cli bash
```{{execute T1}}
```
kubectl exec -it kafka-cli bash
```{{execute T2}}

From **Terminal 1**, create a topic with replication factor of 1. We have Portworx doing replication in this lightweight single Kafka broker configuration. For larger clusters of Kafka the recommended aproach is to use Kafka replication of 3 and Portworx replication of two. Check out why in this blog post [TODO:link to Kafka blog post](http://google.com)
```
./bin/kafka-topics.sh --create --zookeeper zk-headless:2181 --replication-factor 1 --partitions 1 --topic test
```{{execute T1}}

Still in **Terminal 1** Start a message producer and send a couple of messages:
```
./bin/kafka-console-producer.sh --broker-list kafka-broker:9092 --topic test
This is a message
This is another message
```{{execute T1}}

Now receive the messages in **Terminal 2**
```
./bin/kafka-console-consumer.sh --bootstrap-server kafka-broker:9092 --topic test --partition 0 --from-beginning
```{{execute T2}}

Once you're done make sure to ```clear```{{execute interrupt T1}} out of the producer and ```exit```{{execute T1}} from the client shell before continuing:
